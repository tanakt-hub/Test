{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanakt-hub/Test/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOeYGZ3CqvGZ"
      },
      "source": [
        "#ライブラリの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_9il2IAiP5u",
        "outputId": "5d80b493-ae55-4d2f-dd76-b72ad3d6f79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.7/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install mecab-python3 fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "WvUNt_D2rX3K"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import  AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, AdamW, BertConfig, BertJapaneseTokenizer, BertTokenizer, TFBertModel, AutoModel, AutoTokenizer\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSQvIGbE9eUZ"
      },
      "source": [
        "# Mecab関連の準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3sVphWg4Br6",
        "outputId": "c9bc96ed-555f-4b6a-fed9-d9d7467a81b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libmecab-dev is already the newest version (0.996-5).\n",
            "mecab is already the newest version (0.996-5).\n",
            "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-1).\n",
            "file is already the newest version (1:5.32-2ubuntu0.4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "[install-mecab-ipadic-NEologd] : You should execute the following command if you want to install newest version of mecab-ipadic-NEologd\n",
            "\n",
            "    $ bin/install-mecab-ipadic-neologd -n\n",
            "\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
            "[make-mecab-ipadic-NEologd] : Start..\n",
            "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
            "[make-mecab-ipadic-NEologd] : Check local seed file\n",
            "[make-mecab-ipadic-NEologd] : Check local build directory\n",
            "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Original mecab-ipadic file is already there.\n",
            "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Delete old mecab-ipadic-2.7.0-20070801-neologd-20200910 directory\n",
            "mecab-ipadic-2.7.0-20070801/\n",
            "mecab-ipadic-2.7.0-20070801/README\n",
            "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
            "mecab-ipadic-2.7.0-20070801/COPYING\n",
            "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
            "mecab-ipadic-2.7.0-20070801/INSTALL\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
            "mecab-ipadic-2.7.0-20070801/NEWS\n",
            "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
            "mecab-ipadic-2.7.0-20070801/config.guess\n",
            "mecab-ipadic-2.7.0-20070801/config.sub\n",
            "mecab-ipadic-2.7.0-20070801/configure\n",
            "mecab-ipadic-2.7.0-20070801/configure.in\n",
            "mecab-ipadic-2.7.0-20070801/install-sh\n",
            "mecab-ipadic-2.7.0-20070801/missing\n",
            "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
            "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
            "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
            "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
            "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
            "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
            "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
            "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
            "mecab-ipadic-2.7.0-20070801/char.def\n",
            "mecab-ipadic-2.7.0-20070801/feature.def\n",
            "mecab-ipadic-2.7.0-20070801/left-id.def\n",
            "mecab-ipadic-2.7.0-20070801/matrix.def\n",
            "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
            "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
            "mecab-ipadic-2.7.0-20070801/right-id.def\n",
            "mecab-ipadic-2.7.0-20070801/unk.def\n",
            "mecab-ipadic-2.7.0-20070801/dicrc\n",
            "mecab-ipadic-2.7.0-20070801/RESULT\n",
            "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200910\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for working aclocal-1.4... missing\n",
            "checking for working autoconf... missing\n",
            "checking for working automake-1.4... missing\n",
            "checking for working autoheader... missing\n",
            "checking for working makeinfo... missing\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "rm ./Conjunction.csv \n",
            "rm ./Others.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Filler.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Noun.place.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Noun.proper.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "rm ./char.def \n",
            "rm ./left-id.def \n",
            "rm ./matrix.def \n",
            "rm ./feature.def \n",
            "rm ./right-id.def \n",
            "rm ./rewrite.def \n",
            "rm ./unk.def \n",
            "rm ./pos-id.def \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
            "patching file Noun.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Verb.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.adverbal.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.others.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Prefix.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.demonst.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
            "[make-mecab-ipadic-NEologd] : Install adverb entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install interjection entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /content/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent datetime representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent quantity representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /content/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
            "reading ./unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "reading ./Conjunction.csv ... 171\n",
            "reading ./Others.csv ... 2\n",
            "reading ./Noun.demonst.csv ... 120\n",
            "reading ./Noun.adjv.csv ... 3328\n",
            "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
            "reading ./neologd-date-time-infreq-dict-seed.20190415.csv ... 16866\n",
            "reading ./Noun.csv ... 60734\n",
            "reading ./neologd-quantity-infreq-dict-seed.20190415.csv ... 229216\n",
            "reading ./Noun.nai.csv ... 42\n",
            "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
            "reading ./Suffix.csv ... 1448\n",
            "reading ./neologd-adjective-exp-dict-seed.20151126.csv ... 1051146\n",
            "reading ./mecab-user-dict-seed.20200910.csv ... 3224584\n",
            "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
            "reading ./Interjection.csv ... 252\n",
            "reading ./Filler.csv ... 19\n",
            "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
            "reading ./Symbol.csv ... 208\n",
            "reading ./Adverb.csv ... 3032\n",
            "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
            "reading ./Auxil.csv ... 199\n",
            "reading ./Noun.org.csv ... 17149\n",
            "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
            "reading ./Noun.place.csv ... 73194\n",
            "reading ./Noun.number.csv ... 42\n",
            "reading ./Verb.csv ... 130750\n",
            "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
            "reading ./Prefix.csv ... 224\n",
            "reading ./Noun.adverbal.csv ... 808\n",
            "reading ./Adnominal.csv ... 135\n",
            "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
            "reading ./Postp-col.csv ... 91\n",
            "reading ./Noun.others.csv ... 153\n",
            "reading ./Postp.csv ... 146\n",
            "reading ./Noun.verbal.csv ... 12150\n",
            "reading ./Noun.proper.csv ... 27493\n",
            "reading ./Adj.csv ... 27210\n",
            "reading ./Noun.name.csv ... 34215\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200910\n",
            "make: Nothing to be done for 'all'.\n",
            "[make-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic is current user's directory\n",
            "[install-mecab-ipadic-NEologd] : Make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "make[1]: Entering directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200910'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
            " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
            " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
            " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
            " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
            " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
            " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
            " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
            " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
            "make[1]: Leaving directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200910'\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Install completed.\n",
            "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
            "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
            "Usage:\n",
            "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "--2022-09-20 14:53:50--  http://sociocom.jp/~data/2018-manbyo/data/MANBYO_201907_Dic-utf8.dic\n",
            "Resolving sociocom.jp (sociocom.jp)... 49.212.199.94\n",
            "Connecting to sociocom.jp (sociocom.jp)|49.212.199.94|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71728213 (68M)\n",
            "Saving to: ‘MANBYO_201907_Dic-utf8.dic.1’\n",
            "\n",
            "MANBYO_201907_Dic-u 100%[===================>]  68.41M  11.6MB/s    in 5.8s    \n",
            "\n",
            "2022-09-20 14:53:56 (11.9 MB/s) - ‘MANBYO_201907_Dic-utf8.dic.1’ saved [71728213/71728213]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "# MeCab & NEologd\n",
        "!apt install mecab libmecab-dev mecab-ipadic-utf8 file\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -a -y # 公式では -a オプションはついていないが多分必要\n",
        "os.environ['MECABRC'] = \"/etc/mecabrc\" # 環境変数でmecabrcの場所を指定\n",
        "\n",
        "# 万病辞書\n",
        "!wget http://sociocom.jp/~data/2018-manbyo/data/MANBYO_201907_Dic-utf8.dic\n",
        "\n",
        "import subprocess\n",
        "cmd = 'echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "neologd_dic_dir_path = subprocess.check_output(cmd, shell=True).decode('utf-8').strip()\n",
        "\n",
        "# 万病辞書へのパス\n",
        "manbyo_dic_path = 'MANBYO_201907_Dic-utf8.dic'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcfPKFadmOJs"
      },
      "source": [
        "#BERTモデル\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbtShqFwIoY3"
      },
      "source": [
        "## medBERTjp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9CQbC81RvZ_",
        "outputId": "6f1d31b1-9c30-40d1-c77b-5a9207fff2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-20 14:53:57--  https://github.com/ou-medinfo/medbertjp/releases/download/v0.1-minj/medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/306421029/750ea280-155c-11eb-9eb1-dd3e8ea4da0f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220920%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220920T145357Z&X-Amz-Expires=300&X-Amz-Signature=9320a94ebd2ff16d972ed3fcb580a4da9c843b081b3a84225b45f8481336fd83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=306421029&response-content-disposition=attachment%3B%20filename%3DmedBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-20 14:53:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/306421029/750ea280-155c-11eb-9eb1-dd3e8ea4da0f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220920%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220920T145357Z&X-Amz-Expires=300&X-Amz-Signature=9320a94ebd2ff16d972ed3fcb580a4da9c843b081b3a84225b45f8481336fd83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=306421029&response-content-disposition=attachment%3B%20filename%3DmedBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261068341 (249M) [application/octet-stream]\n",
            "Saving to: ‘medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip.1’\n",
            "\n",
            "medBERTjp_L12_H768_ 100%[===================>] 248.97M  8.41MB/s    in 44s     \n",
            "\n",
            "2022-09-20 14:54:42 (5.61 MB/s) - ‘medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip.1’ saved [261068341/261068341]\n",
            "\n",
            "Archive:  medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip\n",
            "replace medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic/pytorch_model.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ou-medinfo/medbertjp/releases/download/v0.1-minj/medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip\n",
        "!unzip medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5bMf-O2R4ni"
      },
      "outputs": [],
      "source": [
        "MEDBERT = 'medBERTjp_L12_H768_A12_WWM_mecab-ipadic-neologd-jmedic'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBiF4Q8gs5hG"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習用データの処理"
      ],
      "metadata": {
        "id": "5ZJvjyQzmgzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moocyn2qF0w3"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "\n",
        "import urllib.request\n",
        "df = pd.read_table(\"https://raw.githubusercontent.com/tanakt-hub/Test/main/data/Label-y1.txt\")\n",
        "\n",
        "# ラベルと文章を分ける\n",
        "labels = df[\"flg\"].values\n",
        "sentences = df[\"text\"].values\n",
        "\n",
        "label_ids = labels\n",
        "\n",
        "# 7:3に学習データとテストデータを分割する\n",
        "train_sentence, test_sentence, y_train, y_test = train_test_split(sentences, label_ids, test_size=0.3, random_state=SEED, stratify=label_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習用クラスと損失関数の定義"
      ],
      "metadata": {
        "id": "yGAv2I--mjKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlyowtlX0Wqh"
      },
      "outputs": [],
      "source": [
        "class TrainDataset():\n",
        "    def __init__(self, toks, targets):\n",
        "        self.toks = toks\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.toks)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        tok = self.toks[item]\n",
        "        target = self.targets[item]\n",
        "\n",
        "        input_ids = torch.tensor(tok[\"input_ids\"])\n",
        "        attention_mask = torch.tensor(tok[\"attention_mask\"])\n",
        "        token_type_ids = torch.tensor(tok[\"token_type_ids\"])\n",
        "        target = torch.tensor(target).float()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"token_type_ids\": token_type_ids,\n",
        "            \"target\": target,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-IVnxy0amJ"
      },
      "outputs": [],
      "source": [
        "class BertClassification(nn.Module):\n",
        "    def __init__(self, model_type, tokenizer):\n",
        "        super(BertClassification, self).__init__()\n",
        "\n",
        "        bert_conf = BertConfig(model_type, output_hidden_states=False, output_attentions=True)\n",
        "        bert_conf.vocab_size = tokenizer.vocab_size\n",
        "\n",
        "        self.bert = AutoModel.from_pretrained(model_type, config=bert_conf, ignore_mismatched_sizes=True)\n",
        "        self.fc = nn.Linear(bert_conf.hidden_size, 1)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        out = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        h = out['pooler_output']\n",
        "        a = out['attentions']\n",
        "        h = nn.ReLU()(h)\n",
        "        h = self.fc(h)\n",
        "        h = h[:, 0]\n",
        "        a = a[-1].sum(1)[:, 0, :]\n",
        "        return h, a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O3zZTEd0gsT"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def train_loop(train_dataloader, model, optimizer, device, tqdm):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    for n_iter, d in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "        target = d[\"target\"].to(device)\n",
        "\n",
        "        output, _ = model(input_ids, attention_mask, token_type_ids)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "    return losses\n",
        "\n",
        "def test_loop(test_dataloader, model, device, tqdm):\n",
        "    losses, predicts = [], []\n",
        "    model.eval()\n",
        "    for n_iter, d in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "        target = d[\"target\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, _ = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "        losses.append(loss.item())\n",
        "        predicts += output.sigmoid().cpu().tolist()\n",
        "\n",
        "    return predicts, np.array(losses).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCOTG9q3ruY_"
      },
      "source": [
        "パラメータとトークナイザの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uLTfY2iSDYW"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = MEDBERT\n",
        "LEAENING_RATE = 1e-6\n",
        "BATCH_SIZE = 30\n",
        "N_EPOCHS = 30\n",
        "\n",
        "TOKENIZER = BertJapaneseTokenizer.from_pretrained(MODEL_TYPE,  mecab_kwargs={ \"mecab_option\": \"-d \" + neologd_dic_dir_path + \" -u \" + manbyo_dic_path})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER.tokenize(\"病理組織学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。脳脊髄液検査では、蛋白 105 mg/dL、細胞数 24/μLで、細菌培養及びウイルス検査は異常なかった。\")"
      ],
      "metadata": {
        "id": "AXWDnY3UcvJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER.batch_encode_plus([\"病理組織学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。脳脊髄液検査では、蛋白 105 mg/dL、細胞数 24/μLで、細菌培養及びウイルス検査は異常なかった。\"])"
      ],
      "metadata": {
        "id": "DWVcb8Src73I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T22rcj4Mr4Fi"
      },
      "source": [
        "学習データとテストデータをともにトークナイズし、dataloaderを定義する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_-XOXXtG6U9"
      },
      "outputs": [],
      "source": [
        "train_toks = []\n",
        "for sent in train_sentence:\n",
        "    tok = TOKENIZER.encode_plus(sent,\n",
        "                                   add_special_tokens=True,\n",
        "                                   max_length=128,\n",
        "                                   pad_to_max_length=True)\n",
        "    train_toks.append(tok)\n",
        "\n",
        "test_toks = []\n",
        "for sent in test_sentence:\n",
        "    tok = TOKENIZER.encode_plus(sent,\n",
        "                                   add_special_tokens=True,\n",
        "                                   max_length=128,\n",
        "                                   pad_to_max_length=True)\n",
        "    test_toks.append(tok)\n",
        "\n",
        "train_dataset = TrainDataset(train_toks, y_train)\n",
        "test_dataset = TrainDataset(test_toks, y_test)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        drop_last=False,\n",
        "        shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_BBcTU7sV8u"
      },
      "source": [
        "学習を行う"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassification(MODEL_TYPE, TOKENIZER)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "NFhUSSyDoKLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYQhjaqmf9ID"
      },
      "outputs": [],
      "source": [
        "model = BertClassification(MODEL_TYPE, TOKENIZER)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEAENING_RATE)\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f\"Epoch-{epoch}\")\n",
        "    train_losses += train_loop(train_dataloader, model, optimizer, device, tqdm)\n",
        "    y_pred, test_loss = test_loop(test_dataloader, model, device, tqdm)\n",
        "\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    # 各epochでのの　Confusion Matrixを確認\n",
        "    _y_pred = (np.array(y_pred) > 0.5).astype(int)\n",
        "    cm = confusion_matrix(y_test, _y_pred)\n",
        "    cm_df = pd.DataFrame(cm,columns=['Predicted Neg', 'Predicted Pos'], index=['Actual Neg', 'Actual Pos'])\n",
        "    display(cm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMX79dp4sozR"
      },
      "source": [
        "学習結果の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkL6kNbIadch"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw9Ym1eua8Xd"
      },
      "outputs": [],
      "source": [
        "plt.plot(test_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_Etbuu5TsS5"
      },
      "source": [
        "# LIMEによる可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFwe66tripfx"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ6liJKuXLm7"
      },
      "outputs": [],
      "source": [
        "def predictor(texts):\n",
        "    tok = TOKENIZER.batch_encode_plus(texts, padding=True)\n",
        "    input_ids = torch.tensor(tok['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(tok['attention_mask']).to(device)\n",
        "    token_type_ids = torch.tensor(tok['token_type_ids']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output, _ = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "    probas = output.sigmoid().cpu().numpy()\n",
        "    return np.vstack([1 - probas, probas]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j8R0hPeYb6w"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=['Neg', 'Pos'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# トライアル"
      ],
      "metadata": {
        "id": "2OidGIyQm3sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "全てのセルの実行完了後は↓のセルのみで実行可能。\n",
        "\n",
        "ダブルクォーテーションの中の文章を好きに入れ替えてCtrl+Enterで実行結果が更新されます。"
      ],
      "metadata": {
        "id": "Y5S-cYSVqI9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "str_to_predict = \"病理組織学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。脳脊髄液検査では、蛋白 105 mg/dL、細胞数 24/μLで、細菌培養及びウイルス検査は異常なかった。\"\n",
        "exp = explainer.explain_instance(str_to_predict, predictor, num_features=20, num_samples=100)\n",
        "exp.show_in_notebook(text=str_to_predict)\n"
      ],
      "metadata": {
        "id": "aYr_XY9tu2_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"病理組織学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。\"\n",
        "str_to_predict = TOKENIZER.tokenize(txt)\n",
        "print(len(txt))\n",
        "print(len(str_to_predict))\n",
        "print(len(predictor(str_to_predict)))\n",
        "print(' '.join(str_to_predict))"
      ],
      "metadata": {
        "id": "gqrAOrsSuD4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor(str_to_predict)"
      ],
      "metadata": {
        "id": "g8YIfdqmKi8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_to_predict"
      ],
      "metadata": {
        "id": "ifoJ_RORNuJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##LimeはSplitterを適切に設定することが必要。たぶん分かち書きしてスペースでくっつけてSplitterを\\sにすればいける。\n",
        "txt = \"病理組織脳脊髄液検査では異常が無かったが、細菌培養及びウイルス検査は異常があった。\"\n",
        "str_to_predict = TOKENIZER.tokenize(txt)\n",
        "txtw = ' '.join(str_to_predict)\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=['Neg', 'Pos'], split_expression=r'\\s', bow=False,)\n",
        "\n",
        "exp = explainer.explain_instance(txtw, predictor, num_features=10, num_samples=1000)\n",
        "exp.show_in_notebook(text=str_to_predict)"
      ],
      "metadata": {
        "id": "ph_4iVzwvcOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "str_to_predict = \"病理組織脳脊髄液検査では、蛋白 105 mg/dL、細胞数 24/μLで、細菌培養及びウイルス検査は異常なかった。学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。\"\n",
        "exp = explainer.explain_instance(str_to_predict, predictor, num_features=20, num_samples=100)\n",
        "exp.show_in_notebook(text=str_to_predict)"
      ],
      "metadata": {
        "id": "SnQooZMnkbQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER.batch_encode_plus(\"ほげろ\", padding=True)"
      ],
      "metadata": {
        "id": "viro4bAzjWGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER.encode_plus(\"ほげろ\", padding=True)"
      ],
      "metadata": {
        "id": "Jtrdb35RjeKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok = TOKENIZER.encode_plus(\"ほげろ\", padding=True, return_tensors = 'pt')\n",
        "input_ids = torch.tensor(tok['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(tok['attention_mask']).to(device)\n",
        "token_type_ids = torch.tensor(tok['token_type_ids']).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(model(input_ids, attention_mask, token_type_ids))"
      ],
      "metadata": {
        "id": "70k1qdLFjpb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = \"病理組織学的所見では、真皮における血管周囲のリンパ球浸潤、並びに表皮における軽度の空胞変性及びリンパ球浸潤などを認めた。\"\n",
        "tok = TOKENIZER.encode_plus(texts, padding=True,  return_tensors = 'pt')\n",
        "tok1 = TOKENIZER.batch_encode_plus(texts, padding=True)\n",
        "print(len(texts))\n",
        "print(tok)\n",
        "print(tok1)"
      ],
      "metadata": {
        "id": "Ue6e9DSeiTe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tok['input_ids'].to(device)\n",
        "attention_mask = tok['attention_mask'].to(device)\n",
        "token_type_ids = tok['token_type_ids'].to(device)\n",
        "\n",
        "print(len(input_ids))\n",
        "with torch.no_grad():\n",
        "    output, _, a = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "probas = output.sigmoid().cpu().numpy()\n",
        "print(probas)"
      ],
      "metadata": {
        "id": "b13-ojiIlDPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor(tok1['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(tok1['attention_mask']).to(device)\n",
        "token_type_ids = torch.tensor(tok1['token_type_ids']).to(device)\n",
        "print(len(input_ids))\n",
        "with torch.no_grad():\n",
        "    output, _, a = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "probas = output.sigmoid().cpu().numpy()\n",
        "print(probas)\n",
        "np.vstack([1 - probas, probas]).T"
      ],
      "metadata": {
        "id": "t3jnYhLHlKYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_ids = torch.tensor(tok['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(tok['attention_mask']).to(device)\n",
        "token_type_ids = torch.tensor(tok['token_type_ids']).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output, _ = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "probas = output.sigmoid().cpu().numpy()\n",
        "return np.vstack([1 - probas, probas]).T"
      ],
      "metadata": {
        "id": "Ql6khMmekmO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NaOY7MUWIS70"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}